/*
Copyright 2022 Upbound Inc.
*/

// Code generated by upjet. DO NOT EDIT.

package v1alpha1

import (
	metav1 "k8s.io/apimachinery/pkg/apis/meta/v1"
	"k8s.io/apimachinery/pkg/runtime/schema"

	v1 "github.com/crossplane/crossplane-runtime/apis/common/v1"
)

type JobInitParameters struct {

	// The kind of the dataset to use with the logpush job. Available values: `access_requests`, `casb_findings`, `firewall_events`, `http_requests`, `spectrum_events`, `nel_reports`, `audit_logs`, `gateway_dns`, `gateway_http`, `gateway_network`, `dns_logs`, `network_analytics_logs`, `workers_trace_events`, `device_posture_results`, `zero_trust_network_sessions`.
	Dataset *string `json:"dataset,omitempty" tf:"dataset,omitempty"`

	// Uniquely identifies a resource (such as an s3 bucket) where data will be pushed. Additional configuration parameters supported by the destination may be included. See [Logpush destination documentation](https://developers.cloudflare.com/logs/reference/logpush-api-configuration#destination).
	DestinationConf *string `json:"destinationConf,omitempty" tf:"destination_conf,omitempty"`

	// Whether to enable the job.
	Enabled *bool `json:"enabled,omitempty" tf:"enabled,omitempty"`

	// Use filters to select the events to include and/or remove from your logs. For more information, refer to [Filters](https://developers.cloudflare.com/logs/reference/logpush-api-configuration/filters/).
	Filter *string `json:"filter,omitempty" tf:"filter,omitempty"`

	// A higher frequency will result in logs being pushed on faster with smaller files. `low` frequency will push logs less often with larger files. Available values: `high`, `low`. Defaults to `high`.
	Frequency *string `json:"frequency,omitempty" tf:"frequency,omitempty"`

	// The kind of logpush job to create. Available values: `edge`, `instant-logs`, `""`.
	Kind *string `json:"kind,omitempty" tf:"kind,omitempty"`

	// Configuration string for the Logshare API. It specifies things like requested fields and timestamp formats. See [Logpush options documentation](https://developers.cloudflare.com/logs/logpush/logpush-configuration-api/understanding-logpush-api/#options).
	LogpullOptions *string `json:"logpullOptions,omitempty" tf:"logpull_options,omitempty"`

	// The maximum uncompressed file size of a batch of logs. Value must be between 5MB and 1GB.
	MaxUploadBytes *float64 `json:"maxUploadBytes,omitempty" tf:"max_upload_bytes,omitempty"`

	// The maximum interval in seconds for log batches. Value must be between 30 and 300.
	MaxUploadIntervalSeconds *float64 `json:"maxUploadIntervalSeconds,omitempty" tf:"max_upload_interval_seconds,omitempty"`

	// The maximum number of log lines per batch. Value must be between 1000 and 1,000,000.
	MaxUploadRecords *float64 `json:"maxUploadRecords,omitempty" tf:"max_upload_records,omitempty"`

	// The name of the logpush job to create.
	Name *string `json:"name,omitempty" tf:"name,omitempty"`

	// Ownership challenge token to prove destination ownership, required when destination is Amazon S3, Google Cloud Storage, Microsoft Azure or Sumo Logic. See [Developer documentation](https://developers.cloudflare.com/logs/logpush/logpush-configuration-api/understanding-logpush-api/#usage).
	OwnershipChallenge *string `json:"ownershipChallenge,omitempty" tf:"ownership_challenge,omitempty"`
}

type JobObservation struct {

	// The account identifier to target for the resource. Must provide only one of `account_id`, `zone_id`.
	AccountID *string `json:"accountId,omitempty" tf:"account_id,omitempty"`

	// The kind of the dataset to use with the logpush job. Available values: `access_requests`, `casb_findings`, `firewall_events`, `http_requests`, `spectrum_events`, `nel_reports`, `audit_logs`, `gateway_dns`, `gateway_http`, `gateway_network`, `dns_logs`, `network_analytics_logs`, `workers_trace_events`, `device_posture_results`, `zero_trust_network_sessions`.
	Dataset *string `json:"dataset,omitempty" tf:"dataset,omitempty"`

	// Uniquely identifies a resource (such as an s3 bucket) where data will be pushed. Additional configuration parameters supported by the destination may be included. See [Logpush destination documentation](https://developers.cloudflare.com/logs/reference/logpush-api-configuration#destination).
	DestinationConf *string `json:"destinationConf,omitempty" tf:"destination_conf,omitempty"`

	// Whether to enable the job.
	Enabled *bool `json:"enabled,omitempty" tf:"enabled,omitempty"`

	// Use filters to select the events to include and/or remove from your logs. For more information, refer to [Filters](https://developers.cloudflare.com/logs/reference/logpush-api-configuration/filters/).
	Filter *string `json:"filter,omitempty" tf:"filter,omitempty"`

	// A higher frequency will result in logs being pushed on faster with smaller files. `low` frequency will push logs less often with larger files. Available values: `high`, `low`. Defaults to `high`.
	Frequency *string `json:"frequency,omitempty" tf:"frequency,omitempty"`

	ID *string `json:"id,omitempty" tf:"id,omitempty"`

	// The kind of logpush job to create. Available values: `edge`, `instant-logs`, `""`.
	Kind *string `json:"kind,omitempty" tf:"kind,omitempty"`

	// Configuration string for the Logshare API. It specifies things like requested fields and timestamp formats. See [Logpush options documentation](https://developers.cloudflare.com/logs/logpush/logpush-configuration-api/understanding-logpush-api/#options).
	LogpullOptions *string `json:"logpullOptions,omitempty" tf:"logpull_options,omitempty"`

	// The maximum uncompressed file size of a batch of logs. Value must be between 5MB and 1GB.
	MaxUploadBytes *float64 `json:"maxUploadBytes,omitempty" tf:"max_upload_bytes,omitempty"`

	// The maximum interval in seconds for log batches. Value must be between 30 and 300.
	MaxUploadIntervalSeconds *float64 `json:"maxUploadIntervalSeconds,omitempty" tf:"max_upload_interval_seconds,omitempty"`

	// The maximum number of log lines per batch. Value must be between 1000 and 1,000,000.
	MaxUploadRecords *float64 `json:"maxUploadRecords,omitempty" tf:"max_upload_records,omitempty"`

	// The name of the logpush job to create.
	Name *string `json:"name,omitempty" tf:"name,omitempty"`

	// Ownership challenge token to prove destination ownership, required when destination is Amazon S3, Google Cloud Storage, Microsoft Azure or Sumo Logic. See [Developer documentation](https://developers.cloudflare.com/logs/logpush/logpush-configuration-api/understanding-logpush-api/#usage).
	OwnershipChallenge *string `json:"ownershipChallenge,omitempty" tf:"ownership_challenge,omitempty"`

	// The zone identifier to target for the resource. Must provide only one of `account_id`, `zone_id`.
	ZoneID *string `json:"zoneId,omitempty" tf:"zone_id,omitempty"`
}

type JobParameters struct {

	// The account identifier to target for the resource. Must provide only one of `account_id`, `zone_id`.
	// +crossplane:generate:reference:type=github.com/clementblaise/provider-cloudflare/apis/account/v1alpha1.Account
	// +kubebuilder:validation:Optional
	AccountID *string `json:"accountId,omitempty" tf:"account_id,omitempty"`

	// Reference to a Account in account to populate accountId.
	// +kubebuilder:validation:Optional
	AccountIDRef *v1.Reference `json:"accountIdRef,omitempty" tf:"-"`

	// Selector for a Account in account to populate accountId.
	// +kubebuilder:validation:Optional
	AccountIDSelector *v1.Selector `json:"accountIdSelector,omitempty" tf:"-"`

	// The kind of the dataset to use with the logpush job. Available values: `access_requests`, `casb_findings`, `firewall_events`, `http_requests`, `spectrum_events`, `nel_reports`, `audit_logs`, `gateway_dns`, `gateway_http`, `gateway_network`, `dns_logs`, `network_analytics_logs`, `workers_trace_events`, `device_posture_results`, `zero_trust_network_sessions`.
	// +kubebuilder:validation:Optional
	Dataset *string `json:"dataset,omitempty" tf:"dataset,omitempty"`

	// Uniquely identifies a resource (such as an s3 bucket) where data will be pushed. Additional configuration parameters supported by the destination may be included. See [Logpush destination documentation](https://developers.cloudflare.com/logs/reference/logpush-api-configuration#destination).
	// +kubebuilder:validation:Optional
	DestinationConf *string `json:"destinationConf,omitempty" tf:"destination_conf,omitempty"`

	// Whether to enable the job.
	// +kubebuilder:validation:Optional
	Enabled *bool `json:"enabled,omitempty" tf:"enabled,omitempty"`

	// Use filters to select the events to include and/or remove from your logs. For more information, refer to [Filters](https://developers.cloudflare.com/logs/reference/logpush-api-configuration/filters/).
	// +kubebuilder:validation:Optional
	Filter *string `json:"filter,omitempty" tf:"filter,omitempty"`

	// A higher frequency will result in logs being pushed on faster with smaller files. `low` frequency will push logs less often with larger files. Available values: `high`, `low`. Defaults to `high`.
	// +kubebuilder:validation:Optional
	Frequency *string `json:"frequency,omitempty" tf:"frequency,omitempty"`

	// The kind of logpush job to create. Available values: `edge`, `instant-logs`, `""`.
	// +kubebuilder:validation:Optional
	Kind *string `json:"kind,omitempty" tf:"kind,omitempty"`

	// Configuration string for the Logshare API. It specifies things like requested fields and timestamp formats. See [Logpush options documentation](https://developers.cloudflare.com/logs/logpush/logpush-configuration-api/understanding-logpush-api/#options).
	// +kubebuilder:validation:Optional
	LogpullOptions *string `json:"logpullOptions,omitempty" tf:"logpull_options,omitempty"`

	// The maximum uncompressed file size of a batch of logs. Value must be between 5MB and 1GB.
	// +kubebuilder:validation:Optional
	MaxUploadBytes *float64 `json:"maxUploadBytes,omitempty" tf:"max_upload_bytes,omitempty"`

	// The maximum interval in seconds for log batches. Value must be between 30 and 300.
	// +kubebuilder:validation:Optional
	MaxUploadIntervalSeconds *float64 `json:"maxUploadIntervalSeconds,omitempty" tf:"max_upload_interval_seconds,omitempty"`

	// The maximum number of log lines per batch. Value must be between 1000 and 1,000,000.
	// +kubebuilder:validation:Optional
	MaxUploadRecords *float64 `json:"maxUploadRecords,omitempty" tf:"max_upload_records,omitempty"`

	// The name of the logpush job to create.
	// +kubebuilder:validation:Optional
	Name *string `json:"name,omitempty" tf:"name,omitempty"`

	// Ownership challenge token to prove destination ownership, required when destination is Amazon S3, Google Cloud Storage, Microsoft Azure or Sumo Logic. See [Developer documentation](https://developers.cloudflare.com/logs/logpush/logpush-configuration-api/understanding-logpush-api/#usage).
	// +kubebuilder:validation:Optional
	OwnershipChallenge *string `json:"ownershipChallenge,omitempty" tf:"ownership_challenge,omitempty"`

	// The zone identifier to target for the resource. Must provide only one of `account_id`, `zone_id`.
	// +crossplane:generate:reference:type=github.com/clementblaise/provider-cloudflare/apis/zone/v1alpha1.Zone
	// +kubebuilder:validation:Optional
	ZoneID *string `json:"zoneId,omitempty" tf:"zone_id,omitempty"`

	// Reference to a Zone in zone to populate zoneId.
	// +kubebuilder:validation:Optional
	ZoneIDRef *v1.Reference `json:"zoneIdRef,omitempty" tf:"-"`

	// Selector for a Zone in zone to populate zoneId.
	// +kubebuilder:validation:Optional
	ZoneIDSelector *v1.Selector `json:"zoneIdSelector,omitempty" tf:"-"`
}

// JobSpec defines the desired state of Job
type JobSpec struct {
	v1.ResourceSpec `json:",inline"`
	ForProvider     JobParameters `json:"forProvider"`
	// THIS IS AN ALPHA FIELD. Do not use it in production. It is not honored
	// unless the relevant Crossplane feature flag is enabled, and may be
	// changed or removed without notice.
	// InitProvider holds the same fields as ForProvider, with the exception
	// of Identifier and other resource reference fields. The fields that are
	// in InitProvider are merged into ForProvider when the resource is created.
	// The same fields are also added to the terraform ignore_changes hook, to
	// avoid updating them after creation. This is useful for fields that are
	// required on creation, but we do not desire to update them after creation,
	// for example because of an external controller is managing them, like an
	// autoscaler.
	InitProvider JobInitParameters `json:"initProvider,omitempty"`
}

// JobStatus defines the observed state of Job.
type JobStatus struct {
	v1.ResourceStatus `json:",inline"`
	AtProvider        JobObservation `json:"atProvider,omitempty"`
}

// +kubebuilder:object:root=true

// Job is the Schema for the Jobs API. <no value>
// +kubebuilder:printcolumn:name="READY",type="string",JSONPath=".status.conditions[?(@.type=='Ready')].status"
// +kubebuilder:printcolumn:name="SYNCED",type="string",JSONPath=".status.conditions[?(@.type=='Synced')].status"
// +kubebuilder:printcolumn:name="EXTERNAL-NAME",type="string",JSONPath=".metadata.annotations.crossplane\\.io/external-name"
// +kubebuilder:printcolumn:name="AGE",type="date",JSONPath=".metadata.creationTimestamp"
// +kubebuilder:subresource:status
// +kubebuilder:resource:scope=Cluster,categories={crossplane,managed,cloudflare}
type Job struct {
	metav1.TypeMeta   `json:",inline"`
	metav1.ObjectMeta `json:"metadata,omitempty"`
	// +kubebuilder:validation:XValidation:rule="!('*' in self.managementPolicies || 'Create' in self.managementPolicies || 'Update' in self.managementPolicies) || has(self.forProvider.dataset) || has(self.initProvider.dataset)",message="dataset is a required parameter"
	// +kubebuilder:validation:XValidation:rule="!('*' in self.managementPolicies || 'Create' in self.managementPolicies || 'Update' in self.managementPolicies) || has(self.forProvider.destinationConf) || has(self.initProvider.destinationConf)",message="destinationConf is a required parameter"
	Spec   JobSpec   `json:"spec"`
	Status JobStatus `json:"status,omitempty"`
}

// +kubebuilder:object:root=true

// JobList contains a list of Jobs
type JobList struct {
	metav1.TypeMeta `json:",inline"`
	metav1.ListMeta `json:"metadata,omitempty"`
	Items           []Job `json:"items"`
}

// Repository type metadata.
var (
	Job_Kind             = "Job"
	Job_GroupKind        = schema.GroupKind{Group: CRDGroup, Kind: Job_Kind}.String()
	Job_KindAPIVersion   = Job_Kind + "." + CRDGroupVersion.String()
	Job_GroupVersionKind = CRDGroupVersion.WithKind(Job_Kind)
)

func init() {
	SchemeBuilder.Register(&Job{}, &JobList{})
}
